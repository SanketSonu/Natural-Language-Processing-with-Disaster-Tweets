{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177f9976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:05.049299Z",
     "iopub.status.busy": "2022-04-02T12:23:05.048482Z",
     "iopub.status.idle": "2022-04-02T12:23:06.887483Z",
     "shell.execute_reply": "2022-04-02T12:23:06.886375Z",
     "shell.execute_reply.started": "2022-03-31T11:38:31.862344Z"
    },
    "papermill": {
     "duration": 1.919453,
     "end_time": "2022-04-02T12:23:06.887680",
     "exception": false,
     "start_time": "2022-04-02T12:23:04.968227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries:\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d7885",
   "metadata": {
    "papermill": {
     "duration": 0.061877,
     "end_time": "2022-04-02T12:23:07.015081",
     "exception": false,
     "start_time": "2022-04-02T12:23:06.953204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c416a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:07.144974Z",
     "iopub.status.busy": "2022-04-02T12:23:07.144276Z",
     "iopub.status.idle": "2022-04-02T12:23:07.214800Z",
     "shell.execute_reply": "2022-04-02T12:23:07.215246Z",
     "shell.execute_reply.started": "2022-03-31T11:38:33.820779Z"
    },
    "papermill": {
     "duration": 0.138214,
     "end_time": "2022-04-02T12:23:07.215393",
     "exception": false,
     "start_time": "2022-04-02T12:23:07.077179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/nlp-getting-started/train.csv')\n",
    "test = pd.read_csv('../input/nlp-getting-started/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b00c14",
   "metadata": {
    "papermill": {
     "duration": 0.061922,
     "end_time": "2022-04-02T12:23:07.339579",
     "exception": false,
     "start_time": "2022-04-02T12:23:07.277657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Removing Keyword and Location variables from both train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f203130f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:07.480463Z",
     "iopub.status.busy": "2022-04-02T12:23:07.470867Z",
     "iopub.status.idle": "2022-04-02T12:23:07.483302Z",
     "shell.execute_reply": "2022-04-02T12:23:07.483731Z",
     "shell.execute_reply.started": "2022-03-31T11:38:33.897685Z"
    },
    "papermill": {
     "duration": 0.082148,
     "end_time": "2022-04-02T12:23:07.483861",
     "exception": false,
     "start_time": "2022-04-02T12:23:07.401713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['keyword','location'], axis = 1)\n",
    "test = test.drop(['keyword','location'], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d29429b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:07.614992Z",
     "iopub.status.busy": "2022-04-02T12:23:07.614265Z",
     "iopub.status.idle": "2022-04-02T12:23:07.617841Z",
     "shell.execute_reply": "2022-04-02T12:23:07.617165Z",
     "shell.execute_reply.started": "2022-03-31T11:38:33.918048Z"
    },
    "papermill": {
     "duration": 0.071537,
     "end_time": "2022-04-02T12:23:07.618005",
     "exception": false,
     "start_time": "2022-04-02T12:23:07.546468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train set: (7613, 3)\n",
      "Shape of Test set: (3263, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking Shape of Train and Test sets:\n",
    "print(\"Shape of Train set:\", train.shape)\n",
    "print(\"Shape of Test set:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eba51d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:07.753571Z",
     "iopub.status.busy": "2022-04-02T12:23:07.752779Z",
     "iopub.status.idle": "2022-04-02T12:23:07.759940Z",
     "shell.execute_reply": "2022-04-02T12:23:07.760463Z",
     "shell.execute_reply.started": "2022-03-31T11:38:33.926539Z"
    },
    "papermill": {
     "duration": 0.078404,
     "end_time": "2022-04-02T12:23:07.760650",
     "exception": false,
     "start_time": "2022-04-02T12:23:07.682246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train set after removing duplicates: (7503, 3)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates of Train set. There are few duplicates in Test set as well,\n",
    "# however, duplicates of Test set can'b be removed because the final test with target has to be uploaded as a submission file\n",
    "\n",
    "train = train.drop_duplicates(subset=['text'], keep='last')\n",
    "print(\"Shape of Train set after removing duplicates:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7377c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:07.904884Z",
     "iopub.status.busy": "2022-04-02T12:23:07.897056Z",
     "iopub.status.idle": "2022-04-02T12:23:08.321121Z",
     "shell.execute_reply": "2022-04-02T12:23:08.320208Z",
     "shell.execute_reply.started": "2022-03-31T11:38:33.941797Z"
    },
    "papermill": {
     "duration": 0.49639,
     "end_time": "2022-04-02T12:23:08.321267",
     "exception": false,
     "start_time": "2022-04-02T12:23:07.824877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[train['text'].map(lambda x: x.isascii())]\n",
    "test[test['text'].map(lambda x: x.isascii())]\n",
    "\n",
    "# Cleaning Tweets\n",
    "def clean_tweets(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+','',text)    # Removing @mentions\n",
    "    text = re.sub(r'#','',text)                 # Removing #tag symbol\n",
    "    text = re.sub(r'RT[\\s]+',' ',text)          # Remvoing RT\n",
    "    text = re.sub(r'\\n','',text) \n",
    "    text = re.sub(r',','',text) \n",
    "    text = re.sub(r'.[.]+','',text) \n",
    "    text = re.sub(r'\\w+:\\/\\/\\S+','',text) \n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text)    # Removing hyperlinks\n",
    "    text = re.sub(r'/',' ',text)\n",
    "    text = re.sub(r'-',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'!','',text)\n",
    "    text = re.sub(r':',' ',text)\n",
    "    text = re.sub(r'$','',text)\n",
    "    text = re.sub(r'%','',text)\n",
    "    text = re.sub(r'^','',text)\n",
    "    text = re.sub(r'&','',text)\n",
    "    text = re.sub(r'=',' ',text)\n",
    "    text = re.sub(r' +',' ',text)               # Removing extra whitespaces\n",
    "\n",
    "    return text\n",
    "\n",
    "# Removing Emojis\n",
    "def clean_emoji(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "train['text'] = train['text'].apply(clean_tweets)    # Applying function to clean tweets\n",
    "train['text'] = train['text'].apply(clean_emoji)     # Applying function to remove emojis\n",
    "train['text'] = train.text.str.lower()               # Making all texts to lower case\n",
    "train['text'] = train['text'].str.strip()            # Removing leading and trailing whitespaces\n",
    "\n",
    "test['text'] = test['text'].apply(clean_tweets)      # Applying function to clean tweets\n",
    "test['text'] = test['text'].apply(clean_emoji)       # Applying function to remove emojis\n",
    "test['text'] = test.text.str.lower()                 # Making all texts to lower case\n",
    "test['text'] = test['text'].str.strip()              # Removing leading and trailing whitespaces\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2788e52",
   "metadata": {
    "papermill": {
     "duration": 0.066716,
     "end_time": "2022-04-02T12:23:08.451714",
     "exception": false,
     "start_time": "2022-04-02T12:23:08.384998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Labels are as follows:\n",
    "'target' -> This denotes whether a tweet is about a real disaster (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c61219b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:08.606708Z",
     "iopub.status.busy": "2022-04-02T12:23:08.604227Z",
     "iopub.status.idle": "2022-04-02T12:23:08.609433Z",
     "shell.execute_reply": "2022-04-02T12:23:08.609995Z",
     "shell.execute_reply.started": "2022-03-31T11:38:34.39627Z"
    },
    "papermill": {
     "duration": 0.085588,
     "end_time": "2022-04-02T12:23:08.610157",
     "exception": false,
     "start_time": "2022-04-02T12:23:08.524569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4307\n",
       "1    3196\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75232e9",
   "metadata": {
    "papermill": {
     "duration": 0.07011,
     "end_time": "2022-04-02T12:23:08.752354",
     "exception": false,
     "start_time": "2022-04-02T12:23:08.682244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setups:\n",
    "\n",
    "Each of our classification models (SVM, Naive Bayes, Logistic Regression, and Random Forest) were\n",
    "tested on the following setups:\n",
    "\n",
    "1. **Setup 1: Removing Punctuation:** All the models are trained and tested after removing punctuations from the corpus.\n",
    "2. **Setup 2: Removing Stop-words:** All the models are trained and tested after removing stop-words from the corpus.\n",
    "3. **Setup 3: Removing Numbers:** All the models are trained and tested after removing numbers from the corpus.\n",
    "4. **Setup 4: Removing Repeating Characters:** All the models are trained and tested after removing repeating characters.\n",
    "5. **Setup 5: Stemming and Lemmatization:** All the models are trained and tested after applying stemming and lemmatization.\n",
    "6. **Setup 6: Setup 1–5:** All the models are trained and tested after removing punctuation, stop-words, numbers, repeating words, stemming and lemmatization.\n",
    "7. **Setup 7: Keeping all above features:** All the models are trained and tested without eliminating any of the above special features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14564f",
   "metadata": {
    "papermill": {
     "duration": 0.06831,
     "end_time": "2022-04-02T12:23:08.890844",
     "exception": false,
     "start_time": "2022-04-02T12:23:08.822534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models:\n",
    "### These models with hyperparameters will be used by all setups, to find the best setup and best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35764c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:09.047105Z",
     "iopub.status.busy": "2022-04-02T12:23:09.046117Z",
     "iopub.status.idle": "2022-04-02T12:23:09.048284Z",
     "shell.execute_reply": "2022-04-02T12:23:09.048744Z",
     "shell.execute_reply.started": "2022-03-31T11:38:34.408355Z"
    },
    "papermill": {
     "duration": 0.087279,
     "end_time": "2022-04-02T12:23:09.048927",
     "exception": false,
     "start_time": "2022-04-02T12:23:08.961648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# making a dictionary with four models with some parameters:\n",
    "\n",
    "model_params = {\n",
    "    \n",
    "    'SVC' :{\n",
    "        'model' : SVC(),\n",
    "        'params' : {\n",
    "            'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf','linear','poly','sigmoid']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'MultinomialNB' :{\n",
    "        'model' : MultinomialNB(),\n",
    "        'params' : {\n",
    "            'alpha' : np.linspace(0.5, 1.5, 6), 'fit_prior' : [True, False]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'logistics_regression' :{\n",
    "        'model' : LogisticRegression(solver = 'lbfgs', multi_class = 'auto'),\n",
    "        'params' : {\n",
    "            'C' : [0.1, 1, 20, 40, 60, 80, 100], 'solver' : ['lbfgs', 'liblinear']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'random_forest' :{\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [80,85,90,95,100], \n",
    "            'max_depth':[20,30,None], 'criterion':['gini','entropy']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584bcb0c",
   "metadata": {
    "papermill": {
     "duration": 0.06856,
     "end_time": "2022-04-02T12:23:09.191254",
     "exception": false,
     "start_time": "2022-04-02T12:23:09.122694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup 1: Models after removing Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510a1c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:09.336191Z",
     "iopub.status.busy": "2022-04-02T12:23:09.335347Z",
     "iopub.status.idle": "2022-04-02T12:23:09.338015Z",
     "shell.execute_reply": "2022-04-02T12:23:09.337524Z",
     "shell.execute_reply.started": "2022-03-31T11:38:34.42222Z"
    },
    "papermill": {
     "duration": 0.078433,
     "end_time": "2022-04-02T12:23:09.338137",
     "exception": false,
     "start_time": "2022-04-02T12:23:09.259704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8cfb7d",
   "metadata": {
    "papermill": {
     "duration": 0.063417,
     "end_time": "2022-04-02T12:23:09.469842",
     "exception": false,
     "start_time": "2022-04-02T12:23:09.406425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1544f3cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:09.602145Z",
     "iopub.status.busy": "2022-04-02T12:23:09.601478Z",
     "iopub.status.idle": "2022-04-02T12:23:09.604122Z",
     "shell.execute_reply": "2022-04-02T12:23:09.604519Z",
     "shell.execute_reply.started": "2022-03-31T11:38:34.432177Z"
    },
    "papermill": {
     "duration": 0.071517,
     "end_time": "2022-04-02T12:23:09.604655",
     "exception": false,
     "start_time": "2022-04-02T12:23:09.533138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e3f5399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:09.738746Z",
     "iopub.status.busy": "2022-04-02T12:23:09.737836Z",
     "iopub.status.idle": "2022-04-02T12:23:09.770353Z",
     "shell.execute_reply": "2022-04-02T12:23:09.769917Z",
     "shell.execute_reply.started": "2022-03-31T11:38:34.439087Z"
    },
    "papermill": {
     "duration": 0.10052,
     "end_time": "2022-04-02T12:23:09.770469",
     "exception": false,
     "start_time": "2022-04-02T12:23:09.669949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5d5e9",
   "metadata": {
    "papermill": {
     "duration": 0.063259,
     "end_time": "2022-04-02T12:23:09.897661",
     "exception": false,
     "start_time": "2022-04-02T12:23:09.834402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52bdb0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:10.042138Z",
     "iopub.status.busy": "2022-04-02T12:23:10.041211Z",
     "iopub.status.idle": "2022-04-02T12:23:10.048485Z",
     "shell.execute_reply": "2022-04-02T12:23:10.048029Z",
     "shell.execute_reply.started": "2022-03-31T11:38:34.475839Z"
    },
    "papermill": {
     "duration": 0.08509,
     "end_time": "2022-04-02T12:23:10.048621",
     "exception": false,
     "start_time": "2022-04-02T12:23:09.963531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe5eb8c",
   "metadata": {
    "papermill": {
     "duration": 0.073276,
     "end_time": "2022-04-02T12:23:10.195320",
     "exception": false,
     "start_time": "2022-04-02T12:23:10.122044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "533ec2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:10.412176Z",
     "iopub.status.busy": "2022-04-02T12:23:10.376476Z",
     "iopub.status.idle": "2022-04-02T12:23:10.945113Z",
     "shell.execute_reply": "2022-04-02T12:23:10.944615Z",
     "shell.execute_reply.started": "2022-03-31T11:38:34.485026Z"
    },
    "papermill": {
     "duration": 0.681168,
     "end_time": "2022-04-02T12:23:10.945245",
     "exception": false,
     "start_time": "2022-04-02T12:23:10.264077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  62381\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89c35a",
   "metadata": {
    "papermill": {
     "duration": 0.069319,
     "end_time": "2022-04-02T12:23:11.087284",
     "exception": false,
     "start_time": "2022-04-02T12:23:11.017965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ed17b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:23:11.232644Z",
     "iopub.status.busy": "2022-04-02T12:23:11.231773Z",
     "iopub.status.idle": "2022-04-02T12:59:53.847159Z",
     "shell.execute_reply": "2022-04-02T12:59:53.846671Z",
     "shell.execute_reply.started": "2022-03-31T11:38:35.081079Z"
    },
    "papermill": {
     "duration": 2202.690643,
     "end_time": "2022-04-02T12:59:53.847290",
     "exception": false,
     "start_time": "2022-04-02T12:23:11.156647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[735 108]\n",
      " [185 473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.80      0.80      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[778  65]\n",
      " [237 421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       843\n",
      "           1       0.87      0.64      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.82      0.78      0.79      1501\n",
      "weighted avg       0.81      0.80      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[708 135]\n",
      " [179 479]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       843\n",
      "           1       0.78      0.73      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.78      0.79      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[767  76]\n",
      " [261 397]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       843\n",
      "           1       0.84      0.60      0.70       658\n",
      "\n",
      "    accuracy                           0.78      1501\n",
      "   macro avg       0.79      0.76      0.76      1501\n",
      "weighted avg       0.79      0.78      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "CPU times: user 26 s, sys: 567 ms, total: 26.6 s\n",
      "Wall time: 36min 42s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.804797</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.798801</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.790806</td>\n",
       "      <td>{'C': 20, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.775483</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 85}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.804797     \n",
       "1  MultinomialNB         0.798801     \n",
       "2  logistics_regression  0.790806     \n",
       "3  random_forest         0.775483     \n",
       "\n",
       "                                                       best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                         \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                \n",
       "2  {'C': 20, 'solver': 'liblinear'}                                 \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 85}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481211b",
   "metadata": {
    "papermill": {
     "duration": 0.071996,
     "end_time": "2022-04-02T12:59:54.021272",
     "exception": false,
     "start_time": "2022-04-02T12:59:53.949276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup 2: Models after removing Stop-words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "412ba8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:59:54.172643Z",
     "iopub.status.busy": "2022-04-02T12:59:54.171732Z",
     "iopub.status.idle": "2022-04-02T12:59:54.173608Z",
     "shell.execute_reply": "2022-04-02T12:59:54.174042Z",
     "shell.execute_reply.started": "2022-03-31T11:42:25.703971Z"
    },
    "papermill": {
     "duration": 0.075553,
     "end_time": "2022-04-02T12:59:54.174183",
     "exception": false,
     "start_time": "2022-04-02T12:59:54.098630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85808a",
   "metadata": {
    "papermill": {
     "duration": 0.067257,
     "end_time": "2022-04-02T12:59:54.307523",
     "exception": false,
     "start_time": "2022-04-02T12:59:54.240266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing Stop-words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "409a1e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:59:54.455175Z",
     "iopub.status.busy": "2022-04-02T12:59:54.454447Z",
     "iopub.status.idle": "2022-04-02T12:59:54.634976Z",
     "shell.execute_reply": "2022-04-02T12:59:54.634528Z",
     "shell.execute_reply.started": "2022-03-31T11:42:25.711063Z"
    },
    "papermill": {
     "duration": 0.258865,
     "end_time": "2022-04-02T12:59:54.635112",
     "exception": false,
     "start_time": "2022-04-02T12:59:54.376247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356dd56",
   "metadata": {
    "papermill": {
     "duration": 0.066486,
     "end_time": "2022-04-02T12:59:54.768410",
     "exception": false,
     "start_time": "2022-04-02T12:59:54.701924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2f18f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:59:54.915112Z",
     "iopub.status.busy": "2022-04-02T12:59:54.914335Z",
     "iopub.status.idle": "2022-04-02T12:59:54.918247Z",
     "shell.execute_reply": "2022-04-02T12:59:54.918613Z",
     "shell.execute_reply.started": "2022-03-31T11:42:25.896215Z"
    },
    "papermill": {
     "duration": 0.080472,
     "end_time": "2022-04-02T12:59:54.918739",
     "exception": false,
     "start_time": "2022-04-02T12:59:54.838267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c406e",
   "metadata": {
    "papermill": {
     "duration": 0.067976,
     "end_time": "2022-04-02T12:59:55.054009",
     "exception": false,
     "start_time": "2022-04-02T12:59:54.986033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bcf51f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:59:55.197553Z",
     "iopub.status.busy": "2022-04-02T12:59:55.196774Z",
     "iopub.status.idle": "2022-04-02T12:59:55.627632Z",
     "shell.execute_reply": "2022-04-02T12:59:55.628071Z",
     "shell.execute_reply.started": "2022-03-31T11:42:25.905771Z"
    },
    "papermill": {
     "duration": 0.507108,
     "end_time": "2022-04-02T12:59:55.628235",
     "exception": false,
     "start_time": "2022-04-02T12:59:55.121127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  51017\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463bf10",
   "metadata": {
    "papermill": {
     "duration": 0.066832,
     "end_time": "2022-04-02T12:59:55.762792",
     "exception": false,
     "start_time": "2022-04-02T12:59:55.695960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb3a9933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T12:59:55.907012Z",
     "iopub.status.busy": "2022-04-02T12:59:55.906024Z",
     "iopub.status.idle": "2022-04-02T13:34:37.974761Z",
     "shell.execute_reply": "2022-04-02T13:34:37.974312Z"
    },
    "papermill": {
     "duration": 2082.14542,
     "end_time": "2022-04-02T13:34:37.974880",
     "exception": false,
     "start_time": "2022-04-02T12:59:55.829460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[728 115]\n",
      " [182 476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.80      0.79      0.80      1501\n",
      "weighted avg       0.80      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[767  76]\n",
      " [220 438]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       843\n",
      "           1       0.85      0.67      0.75       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.79      0.79      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[703 140]\n",
      " [183 475]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       843\n",
      "           1       0.77      0.72      0.75       658\n",
      "\n",
      "    accuracy                           0.78      1501\n",
      "   macro avg       0.78      0.78      0.78      1501\n",
      "weighted avg       0.78      0.78      0.78      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[717 126]\n",
      " [224 434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       843\n",
      "           1       0.78      0.66      0.71       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.77      0.76      0.76      1501\n",
      "weighted avg       0.77      0.77      0.76      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "CPU times: user 19.6 s, sys: 571 ms, total: 20.1 s\n",
      "Wall time: 34min 41s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.802132</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.802798</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>{'C': 40, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.766822</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 80}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.802132     \n",
       "1  MultinomialNB         0.802798     \n",
       "2  logistics_regression  0.784810     \n",
       "3  random_forest         0.766822     \n",
       "\n",
       "                                                    best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                      \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                             \n",
       "2  {'C': 40, 'solver': 'liblinear'}                              \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'n_estimators': 80}  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951cc929",
   "metadata": {
    "papermill": {
     "duration": 0.070903,
     "end_time": "2022-04-02T13:34:38.115816",
     "exception": false,
     "start_time": "2022-04-02T13:34:38.044913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup 3: Models after removing numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583d1415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T13:34:38.318709Z",
     "iopub.status.busy": "2022-04-02T13:34:38.317976Z",
     "iopub.status.idle": "2022-04-02T13:34:38.320404Z",
     "shell.execute_reply": "2022-04-02T13:34:38.319970Z"
    },
    "papermill": {
     "duration": 0.078114,
     "end_time": "2022-04-02T13:34:38.320508",
     "exception": false,
     "start_time": "2022-04-02T13:34:38.242394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3b65d",
   "metadata": {
    "papermill": {
     "duration": 0.070092,
     "end_time": "2022-04-02T13:34:38.460735",
     "exception": false,
     "start_time": "2022-04-02T13:34:38.390643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8069499f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T13:34:38.635848Z",
     "iopub.status.busy": "2022-04-02T13:34:38.635073Z",
     "iopub.status.idle": "2022-04-02T13:34:38.637404Z",
     "shell.execute_reply": "2022-04-02T13:34:38.637005Z"
    },
    "papermill": {
     "duration": 0.106404,
     "end_time": "2022-04-02T13:34:38.637508",
     "exception": false,
     "start_time": "2022-04-02T13:34:38.531104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleaning_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda text: cleaning_numbers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcee9f",
   "metadata": {
    "papermill": {
     "duration": 0.070447,
     "end_time": "2022-04-02T13:34:38.780201",
     "exception": false,
     "start_time": "2022-04-02T13:34:38.709754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967daa28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T13:34:38.928834Z",
     "iopub.status.busy": "2022-04-02T13:34:38.927635Z",
     "iopub.status.idle": "2022-04-02T13:34:38.931057Z",
     "shell.execute_reply": "2022-04-02T13:34:38.931494Z"
    },
    "papermill": {
     "duration": 0.080038,
     "end_time": "2022-04-02T13:34:38.931619",
     "exception": false,
     "start_time": "2022-04-02T13:34:38.851581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136f996",
   "metadata": {
    "papermill": {
     "duration": 0.070718,
     "end_time": "2022-04-02T13:34:39.073328",
     "exception": false,
     "start_time": "2022-04-02T13:34:39.002610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a688aefb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T13:34:39.252224Z",
     "iopub.status.busy": "2022-04-02T13:34:39.247141Z",
     "iopub.status.idle": "2022-04-02T13:34:39.791692Z",
     "shell.execute_reply": "2022-04-02T13:34:39.791002Z"
    },
    "papermill": {
     "duration": 0.648052,
     "end_time": "2022-04-02T13:34:39.791820",
     "exception": false,
     "start_time": "2022-04-02T13:34:39.143768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  60344\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebf87d",
   "metadata": {
    "papermill": {
     "duration": 0.071363,
     "end_time": "2022-04-02T13:34:39.935805",
     "exception": false,
     "start_time": "2022-04-02T13:34:39.864442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c80d1a57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T13:34:40.087613Z",
     "iopub.status.busy": "2022-04-02T13:34:40.086748Z",
     "iopub.status.idle": "2022-04-02T14:10:31.578936Z",
     "shell.execute_reply": "2022-04-02T14:10:31.578474Z"
    },
    "papermill": {
     "duration": 2151.571705,
     "end_time": "2022-04-02T14:10:31.579058",
     "exception": false,
     "start_time": "2022-04-02T13:34:40.007353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[733 110]\n",
      " [187 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.80      0.79      0.80      1501\n",
      "weighted avg       0.80      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[772  71]\n",
      " [236 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.83       843\n",
      "           1       0.86      0.64      0.73       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.78      0.78      1501\n",
      "weighted avg       0.81      0.80      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[706 137]\n",
      " [182 476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       843\n",
      "           1       0.78      0.72      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.78      0.78      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[765  78]\n",
      " [260 398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       843\n",
      "           1       0.84      0.60      0.70       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.79      0.76      0.76      1501\n",
      "weighted avg       0.79      0.77      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "CPU times: user 28.6 s, sys: 1.84 s, total: 30.5 s\n",
      "Wall time: 35min 51s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.802132</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.795470</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.787475</td>\n",
       "      <td>{'C': 40, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.774817</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 90}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.802132     \n",
       "1  MultinomialNB         0.795470     \n",
       "2  logistics_regression  0.787475     \n",
       "3  random_forest         0.774817     \n",
       "\n",
       "                                                    best_params  \n",
       "0  {'C': 100, 'gamma': 0.01, 'kernel': 'sigmoid'}                \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                             \n",
       "2  {'C': 40, 'solver': 'lbfgs'}                                  \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'n_estimators': 90}  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62977c8",
   "metadata": {
    "papermill": {
     "duration": 0.073611,
     "end_time": "2022-04-02T14:10:31.726343",
     "exception": false,
     "start_time": "2022-04-02T14:10:31.652732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup 4: Models after removing repeating characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6232ad4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:10:31.898995Z",
     "iopub.status.busy": "2022-04-02T14:10:31.898116Z",
     "iopub.status.idle": "2022-04-02T14:10:31.900426Z",
     "shell.execute_reply": "2022-04-02T14:10:31.899736Z"
    },
    "papermill": {
     "duration": 0.100213,
     "end_time": "2022-04-02T14:10:31.900585",
     "exception": false,
     "start_time": "2022-04-02T14:10:31.800372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b060c2",
   "metadata": {
    "papermill": {
     "duration": 0.120714,
     "end_time": "2022-04-02T14:10:32.157042",
     "exception": false,
     "start_time": "2022-04-02T14:10:32.036328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing repeating characteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f35d16ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:10:32.410242Z",
     "iopub.status.busy": "2022-04-02T14:10:32.409664Z",
     "iopub.status.idle": "2022-04-02T14:10:34.203930Z",
     "shell.execute_reply": "2022-04-02T14:10:34.203014Z"
    },
    "papermill": {
     "duration": 1.926258,
     "end_time": "2022-04-02T14:10:34.204084",
     "exception": false,
     "start_time": "2022-04-02T14:10:32.277826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = (word_tokenize(i) for i in df.text)\n",
    "df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "def reduce_sequence_word(word):\n",
    "    return ''.join([match.group()[:2] if len(match.group()) > 2 else match.group() for match in pattern.finditer(word)])\n",
    "\n",
    "def reduce_sequence_tweet(tweet):\n",
    "    return [reduce_sequence_word(word) for word in tweet]\n",
    "\n",
    "df.text = df.text.apply(lambda tweet: reduce_sequence_tweet(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b6a2a",
   "metadata": {
    "papermill": {
     "duration": 0.07401,
     "end_time": "2022-04-02T14:10:34.352418",
     "exception": false,
     "start_time": "2022-04-02T14:10:34.278408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8bbf9ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:10:34.520534Z",
     "iopub.status.busy": "2022-04-02T14:10:34.519747Z",
     "iopub.status.idle": "2022-04-02T14:10:34.531244Z",
     "shell.execute_reply": "2022-04-02T14:10:34.531615Z"
    },
    "papermill": {
     "duration": 0.105548,
     "end_time": "2022-04-02T14:10:34.531742",
     "exception": false,
     "start_time": "2022-04-02T14:10:34.426194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text'].astype(str)\n",
    "y = df['target'].astype(str)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdbea8",
   "metadata": {
    "papermill": {
     "duration": 0.073853,
     "end_time": "2022-04-02T14:10:34.680023",
     "exception": false,
     "start_time": "2022-04-02T14:10:34.606170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23798a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:10:34.835857Z",
     "iopub.status.busy": "2022-04-02T14:10:34.835120Z",
     "iopub.status.idle": "2022-04-02T14:10:35.426361Z",
     "shell.execute_reply": "2022-04-02T14:10:35.425883Z"
    },
    "papermill": {
     "duration": 0.673024,
     "end_time": "2022-04-02T14:10:35.426507",
     "exception": false,
     "start_time": "2022-04-02T14:10:34.753483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  62005\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded7570",
   "metadata": {
    "papermill": {
     "duration": 0.07437,
     "end_time": "2022-04-02T14:10:35.577319",
     "exception": false,
     "start_time": "2022-04-02T14:10:35.502949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10273fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:10:35.741550Z",
     "iopub.status.busy": "2022-04-02T14:10:35.740751Z",
     "iopub.status.idle": "2022-04-02T14:46:50.924480Z",
     "shell.execute_reply": "2022-04-02T14:46:50.923109Z"
    },
    "papermill": {
     "duration": 2175.27223,
     "end_time": "2022-04-02T14:46:50.924602",
     "exception": false,
     "start_time": "2022-04-02T14:10:35.652372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[732 111]\n",
      " [187 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.80      0.79      0.80      1501\n",
      "weighted avg       0.80      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[779  64]\n",
      " [233 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       843\n",
      "           1       0.87      0.65      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.82      0.78      0.79      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[703 140]\n",
      " [172 486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       843\n",
      "           1       0.78      0.74      0.76       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.79      0.79      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[771  72]\n",
      " [266 392]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82       843\n",
      "           1       0.84      0.60      0.70       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.79      0.76      0.76      1501\n",
      "weighted avg       0.79      0.77      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "CPU times: user 29.7 s, sys: 1.83 s, total: 31.6 s\n",
      "Wall time: 36min 15s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.801466</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.802132</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.792139</td>\n",
       "      <td>{'C': 80, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.774817</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 95}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.801466     \n",
       "1  MultinomialNB         0.802132     \n",
       "2  logistics_regression  0.792139     \n",
       "3  random_forest         0.774817     \n",
       "\n",
       "                                                       best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                         \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                \n",
       "2  {'C': 80, 'solver': 'lbfgs'}                                     \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 95}  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d9eb3",
   "metadata": {
    "papermill": {
     "duration": 0.078864,
     "end_time": "2022-04-02T14:46:51.082549",
     "exception": false,
     "start_time": "2022-04-02T14:46:51.003685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup 5: Applying Stemming and Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e88fcdbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:46:51.246702Z",
     "iopub.status.busy": "2022-04-02T14:46:51.245131Z",
     "iopub.status.idle": "2022-04-02T14:46:51.247301Z",
     "shell.execute_reply": "2022-04-02T14:46:51.247694Z"
    },
    "papermill": {
     "duration": 0.085448,
     "end_time": "2022-04-02T14:46:51.247821",
     "exception": false,
     "start_time": "2022-04-02T14:46:51.162373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd5349",
   "metadata": {
    "papermill": {
     "duration": 0.078417,
     "end_time": "2022-04-02T14:46:51.404771",
     "exception": false,
     "start_time": "2022-04-02T14:46:51.326354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Applying Stemming: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b47d0361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:46:51.615456Z",
     "iopub.status.busy": "2022-04-02T14:46:51.600334Z",
     "iopub.status.idle": "2022-04-02T14:46:54.186817Z",
     "shell.execute_reply": "2022-04-02T14:46:54.186329Z"
    },
    "papermill": {
     "duration": 2.70407,
     "end_time": "2022-04-02T14:46:54.187070",
     "exception": false,
     "start_time": "2022-04-02T14:46:51.483000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenizing tweets:\n",
    "tokens = (word_tokenize(i) for i in df.text)\n",
    "df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "stemm = SnowballStemmer('english')\n",
    "df['text'] = df['text'].apply(lambda x: [stemm.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf0936",
   "metadata": {
    "papermill": {
     "duration": 0.08589,
     "end_time": "2022-04-02T14:46:54.352166",
     "exception": false,
     "start_time": "2022-04-02T14:46:54.266276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73fb6172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:46:54.535506Z",
     "iopub.status.busy": "2022-04-02T14:46:54.534966Z",
     "iopub.status.idle": "2022-04-02T14:46:54.539771Z",
     "shell.execute_reply": "2022-04-02T14:46:54.540298Z"
    },
    "papermill": {
     "duration": 0.109757,
     "end_time": "2022-04-02T14:46:54.540436",
     "exception": false,
     "start_time": "2022-04-02T14:46:54.430679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text'].astype(str)\n",
    "y = df['target'].astype(str)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dede59",
   "metadata": {
    "papermill": {
     "duration": 0.078012,
     "end_time": "2022-04-02T14:46:54.697317",
     "exception": false,
     "start_time": "2022-04-02T14:46:54.619305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2abbe931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:46:54.897182Z",
     "iopub.status.busy": "2022-04-02T14:46:54.886946Z",
     "iopub.status.idle": "2022-04-02T14:46:55.435585Z",
     "shell.execute_reply": "2022-04-02T14:46:55.435170Z"
    },
    "papermill": {
     "duration": 0.660039,
     "end_time": "2022-04-02T14:46:55.435702",
     "exception": false,
     "start_time": "2022-04-02T14:46:54.775663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  57871\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a90fa15",
   "metadata": {
    "papermill": {
     "duration": 0.079213,
     "end_time": "2022-04-02T14:46:55.594430",
     "exception": false,
     "start_time": "2022-04-02T14:46:55.515217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9583065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T14:46:55.766298Z",
     "iopub.status.busy": "2022-04-02T14:46:55.755702Z",
     "iopub.status.idle": "2022-04-02T15:21:32.600860Z",
     "shell.execute_reply": "2022-04-02T15:21:32.599451Z"
    },
    "papermill": {
     "duration": 2076.927041,
     "end_time": "2022-04-02T15:21:32.600996",
     "exception": false,
     "start_time": "2022-04-02T14:46:55.673955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[709 134]\n",
      " [184 474]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       843\n",
      "           1       0.78      0.72      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.78      0.78      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[774  69]\n",
      " [232 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       843\n",
      "           1       0.86      0.65      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.78      0.79      1501\n",
      "weighted avg       0.81      0.80      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[695 148]\n",
      " [178 480]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       843\n",
      "           1       0.76      0.73      0.75       658\n",
      "\n",
      "    accuracy                           0.78      1501\n",
      "   macro avg       0.78      0.78      0.78      1501\n",
      "weighted avg       0.78      0.78      0.78      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[769  74]\n",
      " [259 399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       843\n",
      "           1       0.84      0.61      0.71       658\n",
      "\n",
      "    accuracy                           0.78      1501\n",
      "   macro avg       0.80      0.76      0.76      1501\n",
      "weighted avg       0.79      0.78      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "CPU times: user 30.3 s, sys: 1.43 s, total: 31.7 s\n",
      "Wall time: 34min 36s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.788141</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.799467</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.782811</td>\n",
       "      <td>{'C': 20, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.778148</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.788141     \n",
       "1  MultinomialNB         0.799467     \n",
       "2  logistics_regression  0.782811     \n",
       "3  random_forest         0.778148     \n",
       "\n",
       "                                                        best_params  \n",
       "0  {'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'}                      \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                 \n",
       "2  {'C': 20, 'solver': 'lbfgs'}                                      \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d6162c",
   "metadata": {
    "papermill": {
     "duration": 0.083188,
     "end_time": "2022-04-02T15:21:32.768013",
     "exception": false,
     "start_time": "2022-04-02T15:21:32.684825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup 6: Models after removing all the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59224e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:32.940498Z",
     "iopub.status.busy": "2022-04-02T15:21:32.938823Z",
     "iopub.status.idle": "2022-04-02T15:21:32.941124Z",
     "shell.execute_reply": "2022-04-02T15:21:32.941548Z"
    },
    "papermill": {
     "duration": 0.091313,
     "end_time": "2022-04-02T15:21:32.941677",
     "exception": false,
     "start_time": "2022-04-02T15:21:32.850364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326943db",
   "metadata": {
    "papermill": {
     "duration": 0.082779,
     "end_time": "2022-04-02T15:21:33.108719",
     "exception": false,
     "start_time": "2022-04-02T15:21:33.025940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing Punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9216d483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:33.309433Z",
     "iopub.status.busy": "2022-04-02T15:21:33.305700Z",
     "iopub.status.idle": "2022-04-02T15:21:33.312611Z",
     "shell.execute_reply": "2022-04-02T15:21:33.312198Z"
    },
    "papermill": {
     "duration": 0.120875,
     "end_time": "2022-04-02T15:21:33.312719",
     "exception": false,
     "start_time": "2022-04-02T15:21:33.191844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "\n",
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0fc209",
   "metadata": {
    "papermill": {
     "duration": 0.082607,
     "end_time": "2022-04-02T15:21:33.478001",
     "exception": false,
     "start_time": "2022-04-02T15:21:33.395394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing Stop-words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31b860d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:33.648795Z",
     "iopub.status.busy": "2022-04-02T15:21:33.648013Z",
     "iopub.status.idle": "2022-04-02T15:21:33.818599Z",
     "shell.execute_reply": "2022-04-02T15:21:33.818161Z"
    },
    "papermill": {
     "duration": 0.257568,
     "end_time": "2022-04-02T15:21:33.818716",
     "exception": false,
     "start_time": "2022-04-02T15:21:33.561148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622bc4f8",
   "metadata": {
    "papermill": {
     "duration": 0.08405,
     "end_time": "2022-04-02T15:21:33.995169",
     "exception": false,
     "start_time": "2022-04-02T15:21:33.911119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing Numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1228c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:34.182102Z",
     "iopub.status.busy": "2022-04-02T15:21:34.176190Z",
     "iopub.status.idle": "2022-04-02T15:21:34.195383Z",
     "shell.execute_reply": "2022-04-02T15:21:34.194839Z"
    },
    "papermill": {
     "duration": 0.11657,
     "end_time": "2022-04-02T15:21:34.195489",
     "exception": false,
     "start_time": "2022-04-02T15:21:34.078919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleaning_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda text: cleaning_numbers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926c26b",
   "metadata": {
    "papermill": {
     "duration": 0.082811,
     "end_time": "2022-04-02T15:21:34.361939",
     "exception": false,
     "start_time": "2022-04-02T15:21:34.279128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Removing repeating characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1928e99b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:34.538542Z",
     "iopub.status.busy": "2022-04-02T15:21:34.537770Z",
     "iopub.status.idle": "2022-04-02T15:21:35.879436Z",
     "shell.execute_reply": "2022-04-02T15:21:35.878943Z"
    },
    "papermill": {
     "duration": 1.43464,
     "end_time": "2022-04-02T15:21:35.879564",
     "exception": false,
     "start_time": "2022-04-02T15:21:34.444924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = (word_tokenize(i) for i in df.text)\n",
    "df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "def reduce_sequence_word(word):\n",
    "    return ''.join([match.group()[:2] if len(match.group()) > 2 else match.group() for match in pattern.finditer(word)])\n",
    "\n",
    "def reduce_sequence_tweet(tweet):\n",
    "    return [reduce_sequence_word(word) for word in tweet]\n",
    "\n",
    "df.text = df.text.apply(lambda tweet: reduce_sequence_tweet(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5af8c",
   "metadata": {
    "papermill": {
     "duration": 0.084444,
     "end_time": "2022-04-02T15:21:36.048881",
     "exception": false,
     "start_time": "2022-04-02T15:21:35.964437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Applying Stemming and Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0873c8af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:36.254510Z",
     "iopub.status.busy": "2022-04-02T15:21:36.253743Z",
     "iopub.status.idle": "2022-04-02T15:21:37.222107Z",
     "shell.execute_reply": "2022-04-02T15:21:37.221098Z"
    },
    "papermill": {
     "duration": 1.089536,
     "end_time": "2022-04-02T15:21:37.222248",
     "exception": false,
     "start_time": "2022-04-02T15:21:36.132712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stemm = SnowballStemmer('english')\n",
    "df['text'] = df['text'].apply(lambda x: [stemm.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ac93d",
   "metadata": {
    "papermill": {
     "duration": 0.083575,
     "end_time": "2022-04-02T15:21:37.392075",
     "exception": false,
     "start_time": "2022-04-02T15:21:37.308500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "038dfb32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:37.574644Z",
     "iopub.status.busy": "2022-04-02T15:21:37.573610Z",
     "iopub.status.idle": "2022-04-02T15:21:37.585906Z",
     "shell.execute_reply": "2022-04-02T15:21:37.585498Z"
    },
    "papermill": {
     "duration": 0.110395,
     "end_time": "2022-04-02T15:21:37.586030",
     "exception": false,
     "start_time": "2022-04-02T15:21:37.475635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text'].astype(str)\n",
    "y = df['target'].astype(str)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d52310",
   "metadata": {
    "papermill": {
     "duration": 0.086571,
     "end_time": "2022-04-02T15:21:37.759344",
     "exception": false,
     "start_time": "2022-04-02T15:21:37.672773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2af78e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:37.952141Z",
     "iopub.status.busy": "2022-04-02T15:21:37.951350Z",
     "iopub.status.idle": "2022-04-02T15:21:38.355652Z",
     "shell.execute_reply": "2022-04-02T15:21:38.356177Z"
    },
    "papermill": {
     "duration": 0.512891,
     "end_time": "2022-04-02T15:21:38.356322",
     "exception": false,
     "start_time": "2022-04-02T15:21:37.843431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  46081\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2e81e",
   "metadata": {
    "papermill": {
     "duration": 0.084441,
     "end_time": "2022-04-02T15:21:38.526361",
     "exception": false,
     "start_time": "2022-04-02T15:21:38.441920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d66bc64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:21:38.708342Z",
     "iopub.status.busy": "2022-04-02T15:21:38.707593Z",
     "iopub.status.idle": "2022-04-02T15:53:21.102743Z",
     "shell.execute_reply": "2022-04-02T15:53:21.101353Z"
    },
    "papermill": {
     "duration": 1902.492577,
     "end_time": "2022-04-02T15:53:21.102860",
     "exception": false,
     "start_time": "2022-04-02T15:21:38.610283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[713 130]\n",
      " [179 479]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       843\n",
      "           1       0.79      0.73      0.76       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.79      0.79      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[760  83]\n",
      " [222 436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       843\n",
      "           1       0.84      0.66      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.78      0.79      1501\n",
      "weighted avg       0.80      0.80      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[701 142]\n",
      " [180 478]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       843\n",
      "           1       0.77      0.73      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.78      0.78      0.78      1501\n",
      "weighted avg       0.78      0.79      0.78      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[728 115]\n",
      " [232 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       843\n",
      "           1       0.79      0.65      0.71       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.77      0.76      0.76      1501\n",
      "weighted avg       0.77      0.77      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "CPU times: user 20.7 s, sys: 602 ms, total: 21.3 s\n",
      "Wall time: 31min 42s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.794137</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.796802</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.785476</td>\n",
       "      <td>{'C': 20, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.768821</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 80}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.794137     \n",
       "1  MultinomialNB         0.796802     \n",
       "2  logistics_regression  0.785476     \n",
       "3  random_forest         0.768821     \n",
       "\n",
       "                                                    best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                      \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                             \n",
       "2  {'C': 20, 'solver': 'liblinear'}                              \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'n_estimators': 80}  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b48da3f",
   "metadata": {
    "papermill": {
     "duration": 0.087074,
     "end_time": "2022-04-02T15:53:21.277488",
     "exception": false,
     "start_time": "2022-04-02T15:53:21.190414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup 7: Models without removing any setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e01c197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:53:21.457041Z",
     "iopub.status.busy": "2022-04-02T15:53:21.456371Z",
     "iopub.status.idle": "2022-04-02T15:53:21.458998Z",
     "shell.execute_reply": "2022-04-02T15:53:21.459431Z"
    },
    "papermill": {
     "duration": 0.095029,
     "end_time": "2022-04-02T15:53:21.459565",
     "exception": false,
     "start_time": "2022-04-02T15:53:21.364536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9711c",
   "metadata": {
    "papermill": {
     "duration": 0.087773,
     "end_time": "2022-04-02T15:53:21.634967",
     "exception": false,
     "start_time": "2022-04-02T15:53:21.547194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92b2c486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:53:21.817698Z",
     "iopub.status.busy": "2022-04-02T15:53:21.816368Z",
     "iopub.status.idle": "2022-04-02T15:53:21.822235Z",
     "shell.execute_reply": "2022-04-02T15:53:21.821386Z"
    },
    "papermill": {
     "duration": 0.09948,
     "end_time": "2022-04-02T15:53:21.822346",
     "exception": false,
     "start_time": "2022-04-02T15:53:21.722866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f67a55",
   "metadata": {
    "papermill": {
     "duration": 0.087749,
     "end_time": "2022-04-02T15:53:22.000807",
     "exception": false,
     "start_time": "2022-04-02T15:53:21.913058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adbd25fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:53:22.189253Z",
     "iopub.status.busy": "2022-04-02T15:53:22.188574Z",
     "iopub.status.idle": "2022-04-02T15:53:22.757710Z",
     "shell.execute_reply": "2022-04-02T15:53:22.756913Z"
    },
    "papermill": {
     "duration": 0.669564,
     "end_time": "2022-04-02T15:53:22.757846",
     "exception": false,
     "start_time": "2022-04-02T15:53:22.088282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  62117\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62598c24",
   "metadata": {
    "papermill": {
     "duration": 0.164872,
     "end_time": "2022-04-02T15:53:23.011685",
     "exception": false,
     "start_time": "2022-04-02T15:53:22.846813",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6685854e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T15:53:23.351110Z",
     "iopub.status.busy": "2022-04-02T15:53:23.344834Z",
     "iopub.status.idle": "2022-04-02T16:29:33.632835Z",
     "shell.execute_reply": "2022-04-02T16:29:33.632379Z"
    },
    "papermill": {
     "duration": 2170.447164,
     "end_time": "2022-04-02T16:29:33.632973",
     "exception": false,
     "start_time": "2022-04-02T15:53:23.185809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[736 107]\n",
      " [187 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.79      0.80      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[777  66]\n",
      " [233 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       843\n",
      "           1       0.87      0.65      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.82      0.78      0.79      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[705 138]\n",
      " [180 478]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       843\n",
      "           1       0.78      0.73      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.78      0.78      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[758  85]\n",
      " [256 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82       843\n",
      "           1       0.83      0.61      0.70       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.79      0.76      0.76      1501\n",
      "weighted avg       0.78      0.77      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "CPU times: user 28.7 s, sys: 1.44 s, total: 30.2 s\n",
      "Wall time: 36min 10s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.804131</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.800799</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.788141</td>\n",
       "      <td>{'C': 40, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.772818</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 95}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.804131     \n",
       "1  MultinomialNB         0.800799     \n",
       "2  logistics_regression  0.788141     \n",
       "3  random_forest         0.772818     \n",
       "\n",
       "                                                    best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                      \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                             \n",
       "2  {'C': 40, 'solver': 'lbfgs'}                                  \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'n_estimators': 95}  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec43a1",
   "metadata": {
    "papermill": {
     "duration": 0.092913,
     "end_time": "2022-04-02T16:29:33.818463",
     "exception": false,
     "start_time": "2022-04-02T16:29:33.725550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating Submission file:\n",
    "It can be observed that **Setup-1 and 7** is performing best for SVM model. **Setup 1** will be used. Let's just train this model with 100% training data. This model will be used for predicting test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a98b3bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:29:34.037231Z",
     "iopub.status.busy": "2022-04-02T16:29:34.036249Z",
     "iopub.status.idle": "2022-04-02T16:29:34.038243Z",
     "shell.execute_reply": "2022-04-02T16:29:34.038694Z"
    },
    "papermill": {
     "duration": 0.111857,
     "end_time": "2022-04-02T16:29:34.038838",
     "exception": false,
     "start_time": "2022-04-02T16:29:33.926981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4701512c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:29:34.274469Z",
     "iopub.status.busy": "2022-04-02T16:29:34.264213Z",
     "iopub.status.idle": "2022-04-02T16:29:34.286038Z",
     "shell.execute_reply": "2022-04-02T16:29:34.285149Z"
    },
    "papermill": {
     "duration": 0.143274,
     "end_time": "2022-04-02T16:29:34.286180",
     "exception": false,
     "start_time": "2022-04-02T16:29:34.142906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "\n",
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2948d339",
   "metadata": {
    "papermill": {
     "duration": 0.093745,
     "end_time": "2022-04-02T16:29:34.478719",
     "exception": false,
     "start_time": "2022-04-02T16:29:34.384974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "213681c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:29:34.670320Z",
     "iopub.status.busy": "2022-04-02T16:29:34.669581Z",
     "iopub.status.idle": "2022-04-02T16:29:34.672229Z",
     "shell.execute_reply": "2022-04-02T16:29:34.671787Z"
    },
    "papermill": {
     "duration": 0.099541,
     "end_time": "2022-04-02T16:29:34.672348",
     "exception": false,
     "start_time": "2022-04-02T16:29:34.572807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Not spliiting, Creating X_train and y_train.\n",
    "# Using 100% data for training SVC model to get better training. Because from Step - 7,\n",
    "# it can be concluded that SVC model with 'TF-IDF Vectorizer (1,2) - unigrams and bigrams' performs best for this dataset\n",
    "\n",
    "\n",
    "X_train = df['text']\n",
    "y_train = df['target']    \n",
    "X_test = test['text']   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0c2b0",
   "metadata": {
    "papermill": {
     "duration": 0.092684,
     "end_time": "2022-04-02T16:29:34.857562",
     "exception": false,
     "start_time": "2022-04-02T16:29:34.764878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58ec681d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:29:35.069323Z",
     "iopub.status.busy": "2022-04-02T16:29:35.068453Z",
     "iopub.status.idle": "2022-04-02T16:29:35.873072Z",
     "shell.execute_reply": "2022-04-02T16:29:35.872524Z"
    },
    "papermill": {
     "duration": 0.922962,
     "end_time": "2022-04-02T16:29:35.873203",
     "exception": false,
     "start_time": "2022-04-02T16:29:34.950241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  74470\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ab373",
   "metadata": {
    "papermill": {
     "duration": 0.09515,
     "end_time": "2022-04-02T16:29:36.063123",
     "exception": false,
     "start_time": "2022-04-02T16:29:35.967973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SVC model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a00b27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:29:36.260725Z",
     "iopub.status.busy": "2022-04-02T16:29:36.259480Z",
     "iopub.status.idle": "2022-04-02T16:51:42.889293Z",
     "shell.execute_reply": "2022-04-02T16:51:42.889704Z"
    },
    "papermill": {
     "duration": 1326.731727,
     "end_time": "2022-04-02T16:51:42.889846",
     "exception": false,
     "start_time": "2022-04-02T16:29:36.158119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best HyperParameter:  {'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "hyperParam = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf','linear','poly','sigmoid']}\n",
    "\n",
    "gsv = GridSearchCV(svc,hyperParam,cv=5,verbose=1,n_jobs=-1)  # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "best_model = gsv.fit(X_train, y_train)                       # Training model with X_train and y_train\n",
    "svc_pred = best_model.predict(X_test)                        # Predicting the results\n",
    "\n",
    "print(\"Best HyperParameter: \", gsv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d52143",
   "metadata": {
    "papermill": {
     "duration": 0.095185,
     "end_time": "2022-04-02T16:51:43.079229",
     "exception": false,
     "start_time": "2022-04-02T16:51:42.984044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc715644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T16:51:43.286119Z",
     "iopub.status.busy": "2022-04-02T16:51:43.285299Z",
     "iopub.status.idle": "2022-04-02T16:51:43.304113Z",
     "shell.execute_reply": "2022-04-02T16:51:43.304565Z"
    },
    "papermill": {
     "duration": 0.125329,
     "end_time": "2022-04-02T16:51:43.304708",
     "exception": false,
     "start_time": "2022-04-02T16:51:43.179379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "<class 'numpy.ndarray'>\n",
      "3263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0     0      1     \n",
       "1     2      1     \n",
       "2     3      1     \n",
       "3     9      0     \n",
       "4     11     1     \n",
       "...   ..    ..     \n",
       "3258  10861  1     \n",
       "3259  10865  1     \n",
       "3260  10868  1     \n",
       "3261  10874  1     \n",
       "3262  10875  1     \n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(svc_pred)\n",
    "print(type(svc_pred))\n",
    "\n",
    "my_array = svc_pred\n",
    "print(len(my_array))\n",
    "\n",
    "submission = pd.DataFrame(my_array,columns = ['target'])\n",
    "submission['id'] = test['id']\n",
    "submission = submission[['id','target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687e300",
   "metadata": {
    "papermill": {
     "duration": 0.094117,
     "end_time": "2022-04-02T16:51:43.511054",
     "exception": false,
     "start_time": "2022-04-02T16:51:43.416937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16128.051375,
   "end_time": "2022-04-02T16:51:44.244622",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-02T12:22:56.193247",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
