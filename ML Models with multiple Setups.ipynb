{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99a4d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sanke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sanke\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries:\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac8d52",
   "metadata": {},
   "source": [
    "# Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98f1011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb16639",
   "metadata": {},
   "source": [
    "#### Removing Keyword and Location variables from both train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd439f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1\n",
       "2   5  All residents asked to 'shelter in place' are ...       1\n",
       "3   6  13,000 people receive #wildfires evacuation or...       1\n",
       "4   7  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['keyword','location'], axis = 1)\n",
    "test = test.drop(['keyword','location'], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f23b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train set: (7613, 3)\n",
      "Shape of Test set: (3263, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking Shape of Train and Test sets:\n",
    "print(\"Shape of Train set:\", train.shape)\n",
    "print(\"Shape of Test set:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578bfa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train set after removing duplicates: (7503, 3)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates of Train set. There are few duplicates in Test set as well,\n",
    "# however, duplicates of Test set can'b be removed because the final test with target has to be uploaded as a submission file\n",
    "\n",
    "train = train.drop_duplicates(subset=['text'], keep='last')\n",
    "print(\"Shape of Train set after removing duplicates:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ac5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['text'].map(lambda x: x.isascii())]\n",
    "test[test['text'].map(lambda x: x.isascii())]\n",
    "\n",
    "# Cleaning Tweets\n",
    "def clean_tweets(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+','',text)    # Removing @mentions\n",
    "    text = re.sub(r'#','',text)                 # Removing #tag symbol\n",
    "    text = re.sub(r'RT[\\s]+',' ',text)          # Remvoing RT\n",
    "    text = re.sub(r'\\n','',text) \n",
    "    text = re.sub(r',','',text) \n",
    "    text = re.sub(r'.[.]+','',text) \n",
    "    text = re.sub(r'\\w+:\\/\\/\\S+','',text) \n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text)    # Removing hyperlinks\n",
    "    text = re.sub(r'/',' ',text)\n",
    "    text = re.sub(r'-',' ',text)\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'!','',text)\n",
    "    text = re.sub(r':',' ',text)\n",
    "    text = re.sub(r'$','',text)\n",
    "    text = re.sub(r'%','',text)\n",
    "    text = re.sub(r'^','',text)\n",
    "    text = re.sub(r'&','',text)\n",
    "    text = re.sub(r'=',' ',text)\n",
    "    text = re.sub(r' +',' ',text)               # Removing extra whitespaces\n",
    "\n",
    "    return text\n",
    "\n",
    "# Removing Emojis\n",
    "def clean_emoji(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "train['text'] = train['text'].apply(clean_tweets)    # Applying function to clean tweets\n",
    "train['text'] = train['text'].apply(clean_emoji)     # Applying function to remove emojis\n",
    "train['text'] = train.text.str.lower()               # Making all texts to lower case\n",
    "train['text'] = train['text'].str.strip()            # Removing leading and trailing whitespaces\n",
    "\n",
    "test['text'] = test['text'].apply(clean_tweets)      # Applying function to clean tweets\n",
    "test['text'] = test['text'].apply(clean_emoji)       # Applying function to remove emojis\n",
    "test['text'] = test.text.str.lower()                 # Making all texts to lower case\n",
    "test['text'] = test['text'].str.strip()              # Removing leading and trailing whitespaces\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172fe56",
   "metadata": {},
   "source": [
    "## Labels are as follows:\n",
    "'target' -> This denotes whether a tweet is about a real disaster (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f96208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4307\n",
       "1    3196\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db7107",
   "metadata": {},
   "source": [
    "# Setups:\n",
    "\n",
    "Each of our classification models (SVM, Naive Bayes, Logistic Regression, and Random Forest) were\n",
    "tested on the following setups:\n",
    "\n",
    "1. **Setup 1: Removing Punctuation:** All the models are trained and tested after removing punctuations from the corpus.\n",
    "2. **Setup 2: Removing Stop-words:** All the models are trained and tested after removing stop-words from the corpus.\n",
    "3. **Setup 3: Removing Numbers:** All the models are trained and tested after removing numbers from the corpus.\n",
    "4. **Setup 4: Removing Repeating Characters:** All the models are trained and tested after removing repeating characters.\n",
    "5. **Setup 5: Stemming and Lemmatization:** All the models are trained and tested after applying stemming and lemmatization.\n",
    "6. **Setup 6: Setup 1–5:** All the models are trained and tested after removing punctuation, stop-words, numbers, repeating words, stemming and lemmatization.\n",
    "7. **Setup 7: Keeping all above features:** All the models are trained and tested without eliminating any of the above special features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919223d",
   "metadata": {},
   "source": [
    "# Models:\n",
    "### These models with hyperparameters will be used by all setups, to find the best setup and best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f5bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dictionary with four models with some parameters:\n",
    "\n",
    "model_params = {\n",
    "    \n",
    "    'SVC' :{\n",
    "        'model' : SVC(),\n",
    "        'params' : {\n",
    "            'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf','linear','poly','sigmoid']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'MultinomialNB' :{\n",
    "        'model' : MultinomialNB(),\n",
    "        'params' : {\n",
    "            'alpha' : np.linspace(0.5, 1.5, 6), 'fit_prior' : [True, False]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'logistics_regression' :{\n",
    "        'model' : LogisticRegression(solver = 'lbfgs', multi_class = 'auto'),\n",
    "        'params' : {\n",
    "            'C' : [0.1, 1, 20, 40, 60, 80, 100], 'solver' : ['lbfgs', 'liblinear']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'random_forest' :{\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : [80,85,90,95,100], \n",
    "            'max_depth':[20,30,None], 'criterion':['gini','entropy']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9620bd9",
   "metadata": {},
   "source": [
    "# Setup 1: Models after removing Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28da8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2c91f0",
   "metadata": {},
   "source": [
    "### Removing Punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127ea243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65504dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4dc3b",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0da2cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6062e8ef",
   "metadata": {},
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74db76aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  62381\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858859f1",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20dc90de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[735 108]\n",
      " [185 473]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.80      0.80      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[778  65]\n",
      " [237 421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       843\n",
      "           1       0.87      0.64      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.82      0.78      0.79      1501\n",
      "weighted avg       0.81      0.80      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[708 135]\n",
      " [179 479]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       843\n",
      "           1       0.78      0.73      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.78      0.79      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[756  87]\n",
      " [259 399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       843\n",
      "           1       0.82      0.61      0.70       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.78      0.75      0.76      1501\n",
      "weighted avg       0.78      0.77      0.76      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 9min 29s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.804797</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.798801</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.790806</td>\n",
       "      <td>{'C': 20, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.769487</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 95}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.804797     \n",
       "1  MultinomialNB         0.798801     \n",
       "2  logistics_regression  0.790806     \n",
       "3  random_forest         0.769487     \n",
       "\n",
       "                                                       best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                         \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                \n",
       "2  {'C': 20, 'solver': 'liblinear'}                                 \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 95}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989389b",
   "metadata": {},
   "source": [
    "# Setup 2: Models after removing Stop-words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c1a4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1035ee33",
   "metadata": {},
   "source": [
    "### Removing Stop-words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c305c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed192be",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70e2499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3289aa",
   "metadata": {},
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b64a0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  51017\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc4a322",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70c094db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[728 115]\n",
      " [182 476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.80      0.79      0.80      1501\n",
      "weighted avg       0.80      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[767  76]\n",
      " [220 438]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       843\n",
      "           1       0.85      0.67      0.75       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.79      0.79      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[703 140]\n",
      " [183 475]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       843\n",
      "           1       0.77      0.72      0.75       658\n",
      "\n",
      "    accuracy                           0.78      1501\n",
      "   macro avg       0.78      0.78      0.78      1501\n",
      "weighted avg       0.78      0.78      0.78      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[722 121]\n",
      " [224 434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81       843\n",
      "           1       0.78      0.66      0.72       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.77      0.76      0.76      1501\n",
      "weighted avg       0.77      0.77      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 8min 53s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.802132</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.802798</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>{'C': 40, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.770153</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': None, 'n_estimators': 80}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.802132     \n",
       "1  MultinomialNB         0.802798     \n",
       "2  logistics_regression  0.784810     \n",
       "3  random_forest         0.770153     \n",
       "\n",
       "                                                    best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                      \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                             \n",
       "2  {'C': 40, 'solver': 'liblinear'}                              \n",
       "3  {'criterion': 'gini', 'max_depth': None, 'n_estimators': 80}  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f86fdd-24ca-4bfb-9ace-201f2ff5626e",
   "metadata": {},
   "source": [
    "# Setup 3: Models after removing numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61499799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab1f9b",
   "metadata": {},
   "source": [
    "### Removing numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a0dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda text: cleaning_numbers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9693436",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df5097c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d0cd08",
   "metadata": {},
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33f0e372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  60344\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a00763",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cfc1415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[733 110]\n",
      " [187 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.80      0.79      0.80      1501\n",
      "weighted avg       0.80      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[772  71]\n",
      " [236 422]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.83       843\n",
      "           1       0.86      0.64      0.73       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.78      0.78      1501\n",
      "weighted avg       0.81      0.80      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[706 137]\n",
      " [182 476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       843\n",
      "           1       0.78      0.72      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.78      0.78      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[769  74]\n",
      " [264 394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82       843\n",
      "           1       0.84      0.60      0.70       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.79      0.76      0.76      1501\n",
      "weighted avg       0.79      0.77      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 9min 40s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.802132</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'sigmoid'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.795470</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.787475</td>\n",
       "      <td>{'C': 40, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.774817</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.802132     \n",
       "1  MultinomialNB         0.795470     \n",
       "2  logistics_regression  0.787475     \n",
       "3  random_forest         0.774817     \n",
       "\n",
       "                                                        best_params  \n",
       "0  {'C': 100, 'gamma': 0.01, 'kernel': 'sigmoid'}                    \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                 \n",
       "2  {'C': 40, 'solver': 'lbfgs'}                                      \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef42cc5",
   "metadata": {},
   "source": [
    "# Setup 4: Models after removing repeating characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c955670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa7589d",
   "metadata": {},
   "source": [
    "### Removing repeating characteres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8e127f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = (word_tokenize(i) for i in df.text)\n",
    "df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "def reduce_sequence_word(word):\n",
    "    return ''.join([match.group()[:2] if len(match.group()) > 2 else match.group() for match in pattern.finditer(word)])\n",
    "\n",
    "def reduce_sequence_tweet(tweet):\n",
    "    return [reduce_sequence_word(word) for word in tweet]\n",
    "\n",
    "df.text = df.text.apply(lambda tweet: reduce_sequence_tweet(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962598af",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4a95f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text'].astype(str)\n",
    "y = df['target'].astype(str)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32969c5",
   "metadata": {},
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "756acbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  62005\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e804b65",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21e27628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[732 111]\n",
      " [187 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.80      0.79      0.80      1501\n",
      "weighted avg       0.80      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[779  64]\n",
      " [233 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       843\n",
      "           1       0.87      0.65      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.82      0.78      0.79      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[702 141]\n",
      " [172 486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       843\n",
      "           1       0.78      0.74      0.76       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.79      0.79      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[753  90]\n",
      " [257 401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81       843\n",
      "           1       0.82      0.61      0.70       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.78      0.75      0.76      1501\n",
      "weighted avg       0.78      0.77      0.76      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 9min 45s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.801466</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.802132</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.791472</td>\n",
       "      <td>{'C': 80, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.768821</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 95}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.801466     \n",
       "1  MultinomialNB         0.802132     \n",
       "2  logistics_regression  0.791472     \n",
       "3  random_forest         0.768821     \n",
       "\n",
       "                                                       best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                         \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                \n",
       "2  {'C': 80, 'solver': 'lbfgs'}                                     \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 95}  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14cd85",
   "metadata": {},
   "source": [
    "# Setup 5: Applying Stemming and Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ad2a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb891f3",
   "metadata": {},
   "source": [
    "### Applying Stemming: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c76c3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing tweets:\n",
    "tokens = (word_tokenize(i) for i in df.text)\n",
    "df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "stemm = SnowballStemmer('english')\n",
    "df['text'] = df['text'].apply(lambda x: [stemm.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa50a6",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a04457b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text'].astype(str)\n",
    "y = df['target'].astype(str)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a44a7",
   "metadata": {},
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19895b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  57846\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7164f7b",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65bc160b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[713 130]\n",
      " [183 475]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       843\n",
      "           1       0.79      0.72      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.78      0.79      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[775  68]\n",
      " [232 426]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       843\n",
      "           1       0.86      0.65      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.82      0.78      0.79      1501\n",
      "weighted avg       0.81      0.80      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[697 146]\n",
      " [177 481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       843\n",
      "           1       0.77      0.73      0.75       658\n",
      "\n",
      "    accuracy                           0.78      1501\n",
      "   macro avg       0.78      0.78      0.78      1501\n",
      "weighted avg       0.78      0.78      0.78      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[769  74]\n",
      " [260 398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       843\n",
      "           1       0.84      0.60      0.70       658\n",
      "\n",
      "    accuracy                           0.78      1501\n",
      "   macro avg       0.80      0.76      0.76      1501\n",
      "weighted avg       0.79      0.78      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 9min 24s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.791472</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.800133</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>{'C': 20, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.777482</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.791472     \n",
       "1  MultinomialNB         0.800133     \n",
       "2  logistics_regression  0.784810     \n",
       "3  random_forest         0.777482     \n",
       "\n",
       "                                                        best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                          \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                 \n",
       "2  {'C': 20, 'solver': 'liblinear'}                                  \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100}  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c0c92",
   "metadata": {},
   "source": [
    "# Setup 6: Models after removing all the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1417d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce35c91",
   "metadata": {},
   "source": [
    "### Removing Punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e5e941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "\n",
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f46e4",
   "metadata": {},
   "source": [
    "### Removing Stop-words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b58b26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (sw)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcbc66d",
   "metadata": {},
   "source": [
    "### Removing Numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "635421f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_numbers(text):\n",
    "    return re.sub('[0-9]+', '', text)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda text: cleaning_numbers(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b44e35",
   "metadata": {},
   "source": [
    "### Removing repeating characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a78fb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = (word_tokenize(i) for i in df.text)\n",
    "df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "pattern = re.compile(r'(.)\\1*')\n",
    "\n",
    "def reduce_sequence_word(word):\n",
    "    return ''.join([match.group()[:2] if len(match.group()) > 2 else match.group() for match in pattern.finditer(word)])\n",
    "\n",
    "def reduce_sequence_tweet(tweet):\n",
    "    return [reduce_sequence_word(word) for word in tweet]\n",
    "\n",
    "df.text = df.text.apply(lambda tweet: reduce_sequence_tweet(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e662e3",
   "metadata": {},
   "source": [
    "### Applying Stemming and Lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d10b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemm = SnowballStemmer('english')\n",
    "df['text'] = df['text'].apply(lambda x: [stemm.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f6684",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9da9816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text'].astype(str)\n",
    "y = df['target'].astype(str)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f8f56",
   "metadata": {},
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29848be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  46081\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b171f",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df2d1bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[713 130]\n",
      " [179 479]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       843\n",
      "           1       0.79      0.73      0.76       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.79      0.79      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[760  83]\n",
      " [222 436]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       843\n",
      "           1       0.84      0.66      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.78      0.79      1501\n",
      "weighted avg       0.80      0.80      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[701 142]\n",
      " [180 478]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       843\n",
      "           1       0.77      0.73      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.78      0.78      0.78      1501\n",
      "weighted avg       0.78      0.79      0.78      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[740 103]\n",
      " [229 429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       843\n",
      "           1       0.81      0.65      0.72       658\n",
      "\n",
      "    accuracy                           0.78      1501\n",
      "   macro avg       0.79      0.76      0.77      1501\n",
      "weighted avg       0.78      0.78      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 8min 21s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.794137</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.796802</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.785476</td>\n",
       "      <td>{'C': 20, 'solver': 'liblinear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.778814</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 80}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.794137     \n",
       "1  MultinomialNB         0.796802     \n",
       "2  logistics_regression  0.785476     \n",
       "3  random_forest         0.778814     \n",
       "\n",
       "                                                       best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                         \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                \n",
       "2  {'C': 20, 'solver': 'liblinear'}                                 \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 80}  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4c010",
   "metadata": {},
   "source": [
    "# Setup 7: Models without removing any setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f83b97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a793987",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9bb80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Train and Test sets:\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e6d13",
   "metadata": {},
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "126d0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  62117\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625295b",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f32fe08a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[[736 107]\n",
      " [187 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       843\n",
      "           1       0.81      0.72      0.76       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.81      0.79      0.80      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "MultinomialNB()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[[777  66]\n",
      " [233 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       843\n",
      "           1       0.87      0.65      0.74       658\n",
      "\n",
      "    accuracy                           0.80      1501\n",
      "   macro avg       0.82      0.78      0.79      1501\n",
      "weighted avg       0.81      0.80      0.80      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "LogisticRegression()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[[705 138]\n",
      " [180 478]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       843\n",
      "           1       0.78      0.73      0.75       658\n",
      "\n",
      "    accuracy                           0.79      1501\n",
      "   macro avg       0.79      0.78      0.78      1501\n",
      "weighted avg       0.79      0.79      0.79      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "RandomForestClassifier()\n",
      "\n",
      "Training the model...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[[762  81]\n",
      " [257 401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82       843\n",
      "           1       0.83      0.61      0.70       658\n",
      "\n",
      "    accuracy                           0.77      1501\n",
      "   macro avg       0.79      0.76      0.76      1501\n",
      "weighted avg       0.78      0.77      0.77      1501\n",
      "\n",
      "\n",
      "Score is appended.\n",
      "\n",
      "Wall time: 9min 43s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.804131</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.800799</td>\n",
       "      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistics_regression</td>\n",
       "      <td>0.788141</td>\n",
       "      <td>{'C': 40, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.774817</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'n_estimators': 85}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  best_score  \\\n",
       "0  SVC                   0.804131     \n",
       "1  MultinomialNB         0.800799     \n",
       "2  logistics_regression  0.788141     \n",
       "3  random_forest         0.774817     \n",
       "\n",
       "                                                       best_params  \n",
       "0  {'C': 1, 'gamma': 1, 'kernel': 'linear'}                         \n",
       "1  {'alpha': 0.5, 'fit_prior': True}                                \n",
       "2  {'C': 40, 'solver': 'lbfgs'}                                     \n",
       "3  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 85}  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# implemented GridSearchCV for four models using a loop and a previously created dictionary\n",
    "# in the created variable 'scores', results are stored for each model such as: model, best_score and best_params.\n",
    "\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'], cv=5, n_jobs=-1, verbose=1) # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "    print(mp['model'])\n",
    "    print('\\nTraining the model...')\n",
    "    best_model = clf.fit(X_train, y_train)                      # Training the model\n",
    "    clf_pred = best_model.predict(X_test)                       # Predicting the results\n",
    "    print(confusion_matrix(y_test,clf_pred))                    # Printing Confusion Matrix\n",
    "    print(metrics.classification_report(y_test, clf_pred))      # Printing Classification Report\n",
    "    scores.append({                                             # Appending results to 'scores' list\n",
    "        'model' : model_name,\n",
    "        'best_score' : best_model.score(X_test, y_test),\n",
    "        'best_params' : clf.best_params_\n",
    "    })\n",
    "    print('\\nScore is appended.\\n')\n",
    "    \n",
    "# Creating data frame with model, best scores and best params:\n",
    "res = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3544f2",
   "metadata": {},
   "source": [
    "# Creating Submission file:\n",
    "It can be observed that **Setup-1 and 7** is performing best for SVM model. **Setup 1** will be used. Let's just train this model with 100% training data. This model will be used for predicting test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3542649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a df that is copy of the train set.\n",
    "df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2755b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "\n",
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b481bc0b",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d3a815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not spliiting, Creating X_train and y_train.\n",
    "# Using 100% data for training SVC model to get better training. Because from Step - 7,\n",
    "# it can be concluded that SVC model with 'TF-IDF Vectorizer (1,2) - unigrams and bigrams' performs best for this dataset\n",
    "\n",
    "\n",
    "X_train = df['text']\n",
    "y_train = df['target']    \n",
    "X_test = test['text']   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcab737",
   "metadata": {},
   "source": [
    "### Transforming dataset using TF-IDF Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48e424a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  74470\n"
     ]
    }
   ],
   "source": [
    "# Extracting features using TF-IDF (1,2) - unigrams and bigrams\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "\n",
    "# Transforming the data using TD-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86088b45",
   "metadata": {},
   "source": [
    "### SVC model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d92261c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best HyperParameter:  {'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "hyperParam = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf','linear','poly','sigmoid']}\n",
    "\n",
    "gsv = GridSearchCV(svc,hyperParam,cv=5,verbose=1,n_jobs=-1)  # Using Cross Validation of 5 and n_jobs=-1 for fast training by using all the processors\n",
    "best_model = gsv.fit(X_train, y_train)                       # Training model with X_train and y_train\n",
    "svc_pred = best_model.predict(X_test)                        # Predicting the results\n",
    "\n",
    "print(\"Best HyperParameter: \", gsv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c1a8f0",
   "metadata": {},
   "source": [
    "### Submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca590bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "<class 'numpy.ndarray'>\n",
      "3263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0     0      1     \n",
       "1     2      1     \n",
       "2     3      1     \n",
       "3     9      0     \n",
       "4     11     1     \n",
       "...   ..    ..     \n",
       "3258  10861  1     \n",
       "3259  10865  1     \n",
       "3260  10868  1     \n",
       "3261  10874  1     \n",
       "3262  10875  1     \n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(svc_pred)\n",
    "print(type(svc_pred))\n",
    "\n",
    "my_array = svc_pred\n",
    "print(len(my_array))\n",
    "\n",
    "submission = pd.DataFrame(my_array,columns = ['target'])\n",
    "submission['id'] = test['id']\n",
    "submission = submission[['id','target']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc514b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
